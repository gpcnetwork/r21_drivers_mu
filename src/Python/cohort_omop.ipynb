{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.request as urlreq\n",
    "import os\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.sql.functions import col, count, mean, sum, avg, stddev, min, max, lit\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "path_to_data = os.path.join(os.getcwd(),'data')\n",
    "path_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"use real_world_data_ed_omop_dec_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def json_to_qry(url_to_json):\n",
    "    json_url = urlreq.urlopen(url_to_json)\n",
    "    json_file = json.loads(json_url.read())\n",
    "    qry_lst = []\n",
    "    def add_quote(lst):\n",
    "        lst_quote = [\"'\"+str(x)+\"'\" for x in lst]\n",
    "        return (lst_quote)\n",
    "    for k,v in json_file.items():\n",
    "        for cd,sig in v.items():\n",
    "            if cd=='long': continue\n",
    "            # entail the range\n",
    "            if 'range' in sig:\n",
    "                for x in sig['range']:\n",
    "                    key_quote = [str(y) for y in list(range(int(x.split('-')[0]),int(x.split('-')[1])+1))]\n",
    "                    sig['exact'].extend(key_quote)\n",
    "\n",
    "            # generate dynamic queries\n",
    "            qry = '''\n",
    "                select ''' + \"'\" + k + \"'\" + ''' as CD_GRP, \n",
    "                       ''' + \"'\" + v['long'] + \"'\" + ''' as CD_GRP_LONG,\n",
    "                       concept_id,concept_name,concept_code,vocabulary_id,domain_id\n",
    "                from concept\n",
    "                where vocabulary_id = '''+ \"'\" + cd.upper() + \"'\" +''' and\n",
    "            '''\n",
    "            if 'icd' in cd and 'pcs' not in cd:\n",
    "                where_lev0 = '''substring_index(concept_code,'.',1) in ('''+ ','.join(add_quote(sig['lev0'])) +''')''' if sig['lev0'] else None\n",
    "                where_lev1 = '''substring(concept_code,1,5) in ('''+ ','.join(add_quote(sig['lev1'])) +''')''' if sig['lev1'] else None\n",
    "                where_lev2 = '''substring(concept_code,1,6) in ('''+ ','.join(add_quote(sig['lev2'])) +''')''' if sig['lev2'] else None\n",
    "                where_nonempty = [s for s in [where_lev0,where_lev1,where_lev2] if s is not None]\n",
    "\n",
    "                qry += '''\n",
    "                (\n",
    "                     ''' + ' or '.join(where_nonempty) + '''  \n",
    "                )         \n",
    "                '''\n",
    "            else:\n",
    "                qry += '''\n",
    "                (\n",
    "                     concept_code in ('''+ ','.join(add_quote(sig['exact'])) +''')\n",
    "                )         \n",
    "                '''\n",
    "            qry_lst.append(qry)\n",
    "            \n",
    "    return qry_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load delivery code list and save as a temp view\n",
    "qry_lst = json_to_qry('https://raw.githubusercontent.com/RWD2E/phecdm/main/res/valueset_curated/vs-mmm-delivery.json')\n",
    "\n",
    "delivery_omop_meta = spark.sql(' union all '.join(qry_lst)).cache()\n",
    "delivery_omop_meta.createOrReplaceTempView(\"delivery_omop_meta\")\n",
    "delivery_omop_meta.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_init = spark.sql('''\n",
    "    select obs.person_id,\n",
    "           obs.visit_occurrence_id, \n",
    "           obs.observation_date as event_date, \n",
    "           m.CD_GRP as delivery_type,\n",
    "           m.vocabulary_id as event_source\n",
    "    from observation obs\n",
    "    join delivery_omop_meta m\n",
    "    on obs.observation_concept_id = m.concept_id\n",
    "    where upper(m.vocabulary_id) in ('DRG') \n",
    "    union all\n",
    "    select px.person_id,\n",
    "           px.visit_occurrence_id, \n",
    "           px.procedure_date as event_date,\n",
    "           m.CD_GRP as delivery_type,\n",
    "           m.vocabulary_id as event_source\n",
    "    from procedure_occurrence px\n",
    "    join delivery_omop_meta m\n",
    "    on px.procedure_concept_id = m.concept_id\n",
    "    where upper(m.vocabulary_id) in ('CPT4','HCPCS','ICD9PROC','ICD10PCS')\n",
    "    union all\n",
    "    select dx.person_id,\n",
    "           dx.visit_occurrence_id, \n",
    "           dx.condition_start_date as event_date,\n",
    "           m.CD_GRP as delivery_type,\n",
    "           m.vocabulary_id as event_source\n",
    "    from condition_occurrence dx\n",
    "    join delivery_omop_meta m\n",
    "    on dx.condition_concept_id = m.concept_id\n",
    "    where upper(m.vocabulary_id) in ('ICD9CM','ICD10CM')\n",
    "''').cache()\n",
    "delivery_init.createOrReplaceTempView(\"delivery_init\")\n",
    "# delivery_init.write.saveAsTable(\"delivery_init\")\n",
    "delivery_init.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "    select event_source, count(distinct person_id)\n",
    "    from delivery_init\n",
    "    group by event_source \n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tevent_source\tcount(DISTINCT person_id)\n",
    "0\tCPT4\t369241\n",
    "1\tICD10PCS\t1318294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "    select delivery_type, count(distinct person_id)\n",
    "    from delivery_init\n",
    "    group by delivery_type \n",
    "''').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tdelivery_type\tcount(DISTINCT person_id)\n",
    "0\td_v\t954939\n",
    "1\td_c\t582741\n",
    "2\td_e\t7196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_ip = spark.sql('''\n",
    "    select distinct\n",
    "           a.person_id, \n",
    "           a.visit_occurrence_id,\n",
    "           v.visit_start_date,\n",
    "           v.visit_end_date,\n",
    "           v.care_site_id\n",
    "    from delivery_init a \n",
    "    join visit_occurrence v \n",
    "    on a.person_id = v.person_id and \n",
    "       a.visit_occurrence_id = v.visit_occurrence_id\n",
    "    where v.visit_concept_id in (\n",
    "            9201, -- IP\n",
    "            9203 -- ED\n",
    "         ) or \n",
    "         v.visit_source_value in (\n",
    "        'I|2.16.840.1.113883.12.4|Inpatient',\n",
    "        'P|2.16.840.1.113883.12.4|Preadmit',\n",
    "        'E|2.16.840.1.113883.12.4|Emergency',\n",
    "        'B|2.16.840.1.113883.12.4|Obstetrics'\n",
    "        )\n",
    "''').cache()\n",
    "delivery_ip.createOrReplaceTempView(\"delivery_ip\")\n",
    "delivery_ip.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_consolidate = spark.sql('''\n",
    "    with cd_filter as (\n",
    "        select v.person_id, \n",
    "               v.visit_occurrence_id,\n",
    "               v.care_site_id,\n",
    "               v.visit_start_date,\n",
    "               v.visit_end_date,\n",
    "               a.delivery_type,\n",
    "               a.event_source,\n",
    "               a.event_date,\n",
    "               row_number() over (partition by v.person_id, v.visit_occurrence_id, a.event_source order by a.event_date) as rn_asc,\n",
    "               row_number() over (partition by v.person_id, v.visit_occurrence_id, a.event_source order by a.event_date desc) as rn_desc\n",
    "        from delivery_ip v\n",
    "        join delivery_init a \n",
    "        on v.person_id = a.person_id and \n",
    "           v.visit_occurrence_id = a.visit_occurrence_id\n",
    "        where a.event_date between date_sub(v.visit_start_date,3) and date_add(v.visit_end_date,3)\n",
    "    ), f_pvt as (\n",
    "        select * \n",
    "        from (\n",
    "            select person_id, visit_occurrence_id,\n",
    "                   event_source, event_date\n",
    "            from cd_filter\n",
    "            where rn_asc = 1       \n",
    "        )\n",
    "        pivot (\n",
    "            min(event_date) for event_source in (\n",
    "                'DRG' as F_DRG_DT,'CPT4' as F_CPT_DT,'ICD10PCS' as F_ICD_DT\n",
    "            )\n",
    "        )\n",
    "    ), l_pvt as (\n",
    "        select * \n",
    "        from (\n",
    "            select person_id, visit_occurrence_id,\n",
    "                   event_source, event_date\n",
    "            from cd_filter\n",
    "            where rn_desc = 1       \n",
    "        )\n",
    "        pivot (\n",
    "            max(event_date) for event_source in (\n",
    "                'DRG' as L_DRG_DT,'CPT4' as L_CPT_DT,'ICD10PCS' as L_ICD_DT\n",
    "            )\n",
    "        )\n",
    "    ), dtype_pvt as (\n",
    "        select * \n",
    "        from (\n",
    "            select person_id, visit_occurrence_id,\n",
    "                   event_source, delivery_type\n",
    "            from cd_filter\n",
    "            where rn_desc = 1 \n",
    "        )\n",
    "        pivot (\n",
    "            max(delivery_type) for event_source in (\n",
    "                'DRG' as DTYPE_DRG,'CPT4' as DTYPE_CPT,'ICD10PCS' as DTYPE_ICD\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    select a.person_id, \n",
    "           a.visit_occurrence_id,\n",
    "           a.visit_start_date,\n",
    "           a.visit_end_date,\n",
    "           a.care_site_id,\n",
    "           f.F_DRG_DT,l.L_DRG_DT,d.DTYPE_DRG,\n",
    "           f.F_CPT_DT,l.L_CPT_DT,d.DTYPE_CPT,\n",
    "           f.F_ICD_DT,l.L_ICD_DT,d.DTYPE_ICD\n",
    "    from delivery_ip a \n",
    "    left join f_pvt f on a.person_id = f.person_id and a.visit_occurrence_id = f.visit_occurrence_id\n",
    "    left join l_pvt l on a.person_id = l.person_id and a.visit_occurrence_id = l.visit_occurrence_id\n",
    "    left join dtype_pvt d on a.person_id = d.person_id and a.visit_occurrence_id = d.visit_occurrence_id\n",
    "''').cache()\n",
    "delivery_consolidate.createOrReplaceTempView(\"delivery_consolidate\")\n",
    "# delivery_consolidate.write.mode('overwrite').saveAsTable(\"delivery_consolidate\")\n",
    "delivery_consolidate.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Row(person_id=2, event_id=1, visit_occurrence_id=16982301016989, care_site_source_value='1', delivery_type='d_c', event_start_date=datetime.date(2019, 5, 2), event_end_date=datetime.date(2019, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_elig = spark.sql('''\n",
    "    with date_consolid as (\n",
    "        select distinct \n",
    "               person_id,\n",
    "               visit_occurrence_id,\n",
    "               care_site_id,\n",
    "               coalesce(DTYPE_DRG,DTYPE_ICD,DTYPE_CPT) as delivery_type,\n",
    "               coalesce(F_DRG_DT,visit_start_date,F_ICD_DT,F_CPT_DT) as event_start_dt,\n",
    "               coalesce(L_DRG_DT,visit_end_date,L_ICD_DT,L_CPT_DT) as event_end_dt\n",
    "        from delivery_consolidate    \n",
    "    ), visit_diffs as (\n",
    "        select a.*, \n",
    "               lag(a.event_start_dt, 1, '1899-12-31') OVER (PARTITION BY person_id ORDER BY event_start_dt) AS last_event_start_dt\n",
    "        from date_consolid a \n",
    "    ), visit_session as (\n",
    "        select b.*, \n",
    "               case \n",
    "                   when datediff(b.event_start_dt,b.last_event_start_dt) > 211 then 1\n",
    "                   else 0 \n",
    "               end as new_session_flag\n",
    "        from visit_diffs b\n",
    "    ), sessions as (\n",
    "        select d.*, \n",
    "               sum(d.new_session_flag) over (PARTITION BY d.person_id ORDER BY d.event_start_dt) as event_id\n",
    "        from visit_session d\n",
    "    ), session_order as (\n",
    "        select e.*, \n",
    "               row_number() over (partition by e.person_id, e.event_id order by e.event_start_dt) as rn,\n",
    "               max(e.event_end_dt) over (partition by e.person_id, e.event_id) as event_end_date\n",
    "    from sessions e\n",
    "    )\n",
    "    select s.person_id, \n",
    "           s.event_id, \n",
    "           s.visit_occurrence_id,\n",
    "           cs.care_site_source_value,\n",
    "           s.delivery_type,\n",
    "           s.event_start_dt as event_start_date,\n",
    "           s.event_end_date\n",
    "    from session_order s \n",
    "    join care_site cs on s.care_site_id = cs.care_site_id\n",
    "    where s.rn = 1\n",
    "    order by s.person_id, s.event_id\n",
    "''').cache()\n",
    "# delivery_elig.createOrReplaceTempView(\"delivery_elig\")\n",
    "delivery_elig.write.mode('overwrite').saveAsTable(\"delivery_elig\")\n",
    "delivery_elig.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=2, event_id=1, visit_occurrence_id=16982301016989, care_site_source_value='1', delivery_type='d_c', event_start_date=datetime.date(2019, 5, 2), event_end_date=datetime.date(2019, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_elig_tbl1 = spark.sql('''\n",
    "    select d.person_id,\n",
    "           d.event_id,\n",
    "           d.event_start_date, \n",
    "           d.event_end_date,\n",
    "           d.delivery_type,\n",
    "           coalesce(datediff(d.event_end_date,d.event_start_date),0) as los, \n",
    "           d.visit_occurrence_id,\n",
    "           p.year_of_birth,\n",
    "           year(d.event_start_date) - p.year_of_birth as age_at_event,\n",
    "           --p.month_of_birth,\n",
    "           --p.day_of_birth,\n",
    "           p.race_source_value,\n",
    "           p.ethnicity_source_value,\n",
    "           p.location_id,\n",
    "           p.care_site_id,\n",
    "           d.care_site_source_value,\n",
    "           coalesce(tnt.bed_size,'NI') as bed_size,\n",
    "           tnt.speciality,\n",
    "           tnt.segment,\n",
    "           tnt.zip_code,\n",
    "           dth.death_date,\n",
    "           case when dth.death_date is not null then 1 else 0 end as death_ind,\n",
    "           row_number() over (partition by d.person_id order by d.event_start_date) as delivery_idx\n",
    "    from delivery_elig d\n",
    "    join person p on d.person_id = p.person_id\n",
    "    left join tenant_attributes tnt on d.care_site_source_value = tnt.tenant\n",
    "    left join death dth on d.person_id = dth.person_id \n",
    "    where year(d.event_start_date) - p.year_of_birth between 10 and 55\n",
    "''').cache()\n",
    "delivery_elig_tbl1.createOrReplaceTempView(\"delivery_elig_tbl1\")\n",
    "delivery_elig_tbl1.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=11567, event_id=1, event_start_date=datetime.date(2024, 3, 4), event_end_date=datetime.date(2024, 3, 5), delivery_type='d_v', los=1, visit_occurrence_id=17454747617679, year_of_birth=1990, age_at_event=34, race_source_value='American Indian or Alaska Native', ethnicity_source_value='Non-Hispanic', location_id=23, care_site_id=101, care_site_source_value='1', bed_size='200-299', speciality='Acute Care Hospital', segment='Hospital', zip_code='8', death_date=None, death_ind=0, delivery_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load SMM code list and get omop concept_id\n",
    "qry_lst = json_to_qry('https://raw.githubusercontent.com/RWD2E/phecdm/main/res/valueset_curated/vs-mmm-smm.json')\n",
    "\n",
    "smm_omop_meta = spark.sql(' union all '.join(qry_lst)).cache()\n",
    "smm_omop_meta.createOrReplaceTempView(\"smm_omop_meta\")\n",
    "smm_omop_meta.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(CD_GRP='ami', CD_GRP_LONG='acute myocardial infarction', concept_id=44832372, concept_name='Acute myocardial infarction', concept_code='410', vocabulary_id='ICD9CM', domain_id='Condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "smm_init = spark.sql('''\n",
    "    select px.person_id,\n",
    "           px.visit_occurrence_id, \n",
    "           px.procedure_date as event_date,\n",
    "           m.CD_GRP as SMM_GRP\n",
    "    from procedure_occurrence px\n",
    "    join smm_omop_meta m\n",
    "    on px.procedure_concept_id = m.concept_id\n",
    "    where upper(m.vocabulary_id) in ('CPT4','HCPCS','ICD9PROC','ICD10PCS')\n",
    "    union all\n",
    "    select person_id,\n",
    "           visit_occurrence_id, \n",
    "           condition_start_date as event_date,\n",
    "           m.CD_GRP as SMM_GRP\n",
    "    from condition_occurrence dx\n",
    "    join smm_omop_meta m\n",
    "    on dx.condition_concept_id = m.concept_id\n",
    "    where upper(m.vocabulary_id) in ('ICD9CM','ICD10CM')\n",
    "''').cache()\n",
    "smm_init.createOrReplaceTempView(\"smm_init\")\n",
    "smm_init.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=89592, visit_occurrence_id=17858474179383, event_date=datetime.date(2022, 11, 18), SMM_GRP='hys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "smm_post_delivery = spark.sql('''\n",
    "    select a.person_id, b.event_id,\n",
    "           a.SMM_GRP,\n",
    "           b.event_start_date,a.event_date,\n",
    "           datediff(a.event_date,b.event_start_date) AS days_since_index,\n",
    "           b.delivery_idx\n",
    "    from smm_init a \n",
    "    join delivery_elig_tbl1 b \n",
    "    on a.person_id = b.person_id\n",
    "    where datediff(a.event_date,b.event_start_date) between 0 and 365\n",
    "''').cache()\n",
    "smm_post_delivery.createOrReplaceTempView(\"smm_post_delivery\")\n",
    "smm_post_delivery.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=29089, event_id=1, SMM_GRP='bpt', event_start_date=datetime.date(2021, 9, 3), event_date=datetime.date(2021, 9, 3), days_since_index=0, delivery_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "smm_post_delivery_wide = spark.sql('''\n",
    "    select *\n",
    "    from (\n",
    "        select person_id, event_id, SMM_GRP,days_since_index\n",
    "        from smm_post_delivery\n",
    "     )\n",
    "    pivot \n",
    "    (\n",
    "        min(days_since_index) for SMM_GRP in (\n",
    "            'ami' as AMI_since_index,\n",
    "            'ane' as ANE_since_index,\n",
    "            'arf' as ARF_since_index,\n",
    "            'ards' as ARDS_since_index,\n",
    "            'afe' as AFE_since_index,\n",
    "            'cavf' as CAVF_since_index,\n",
    "            'cocr' as COCR_since_index,\n",
    "            'dic' as DIC_since_index,\n",
    "            'ecl' as ECL_since_index,\n",
    "            'hf' as HF_since_index,\n",
    "            'pcd' as PCD_since_index,\n",
    "            'pe' as PE_since_index,\n",
    "            'sac' as SAC_since_index,\n",
    "            'sep' as SEP_since_index,\n",
    "            'ssh' as SSH_since_index,\n",
    "            'scc' as SCC_since_index,\n",
    "            'ate' as ATE_since_index,\n",
    "            'bpt' as BPT_since_index,\n",
    "            'hys' as HYS_since_index,\n",
    "            'tt' as TT_since_index,\n",
    "            'ven' as VEN_since_index\n",
    "        )\n",
    "    )\n",
    "''').cache()\n",
    "smm_post_delivery_wide.createOrReplaceTempView(\"smm_post_delivery_wide\")\n",
    "smm_post_delivery_wide.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=8591935406, event_id=1, AMI_since_index=None, ANE_since_index=None, ARF_since_index=None, ARDS_since_index=None, AFE_since_index=None, CAVF_since_index=None, COCR_since_index=None, DIC_since_index=None, ECL_since_index=None, HF_since_index=None, PCD_since_index=None, PE_since_index=None, SAC_since_index=None, SEP_since_index=None, SSH_since_index=None, SCC_since_index=None, ATE_since_index=None, BPT_since_index=1, HYS_since_index=None, TT_since_index=None, VEN_since_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_elig_censor = spark.sql('''\n",
    "    select a.person_id, a.event_id,\n",
    "           max(coalesce(a.death_date,v.visit_end_date,v.visit_start_date)) as censor_date,\n",
    "           datediff(max(coalesce(a.death_date,v.visit_end_date,v.visit_start_date)),a.event_start_date) as censor_since_index\n",
    "    from delivery_elig_tbl1 a \n",
    "    join visit_occurrence v\n",
    "    on a.person_id = v.person_id\n",
    "    group by a.person_id,a.event_id,a.event_start_date\n",
    "''').cache()\n",
    "delivery_elig_censor.createOrReplaceTempView(\"delivery_elig_censor\")\n",
    "delivery_elig_censor.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=11567, censor_date=datetime.date(2024, 8, 23), censor_since_index=172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load comorb code list and get omop concept_id\n",
    "qry2_lst = json_to_qry('https://raw.githubusercontent.com/RWD2E/phecdm/main/res/valueset_curated/vs-comorb.json')\n",
    "\n",
    "comorb_omop_meta = spark.sql(' union all '.join(qry2_lst)).cache()\n",
    "comorb_omop_meta.createOrReplaceTempView(\"comorb_omop_meta\")\n",
    "comorb_omop_meta.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "comorb_init = spark.sql('''\n",
    "    select person_id,\n",
    "           visit_occurrence_id, \n",
    "           condition_start_date as event_date,\n",
    "           m.CD_GRP as COMORB_GRP\n",
    "    from condition_occurrence dx\n",
    "    join comorb_omop_meta m\n",
    "    on dx.condition_source_concept_id = m.concept_id\n",
    "    where upper(m.vocabulary_id) in ('ICD9CM','ICD10CM')\n",
    "''').cache()\n",
    "comorb_init.createOrReplaceTempView(\"comorb_init\")\n",
    "comorb_init.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=438087336549, visit_occurrence_id=16303696311690, event_date=datetime.date(2019, 12, 4), COMORB_GRP='copd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "comorb_pre_delivery = spark.sql('''\n",
    "    select a.person_id, b.event_id,\n",
    "           a.COMORB_GRP,\n",
    "           b.event_start_date,a.event_date,\n",
    "           datediff(a.event_date,b.event_start_date) AS days_since_index,\n",
    "           b.delivery_idx\n",
    "    from comorb_init a \n",
    "    join delivery_elig_tbl1 b \n",
    "    on a.person_id = b.person_id\n",
    "    where datediff(a.event_date,b.event_start_date) < 0\n",
    "''').cache()\n",
    "comorb_pre_delivery.createOrReplaceTempView(\"comorb_pre_delivery\")\n",
    "comorb_pre_delivery.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=11567, event_id=1, COMORB_GRP='covid', event_start_date=datetime.date(2024, 3, 4), event_date=datetime.date(2022, 8, 22), days_since_index=-560, delivery_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "comorb_pre_delivery_wide = spark.sql('''\n",
    "    select *\n",
    "    from (\n",
    "        select person_id, event_id, COMORB_GRP,days_since_index\n",
    "        from comorb_pre_delivery\n",
    "     )\n",
    "    pivot \n",
    "    (\n",
    "        min(days_since_index) for COMORB_GRP in (\n",
    "            'hep' as hist_HEP_since_index,\n",
    "            'ihd' as hist_IHD_since_index,\n",
    "            'ast' as hist_AST_since_index,\n",
    "            'liv' as hist_LIV_since_index,\n",
    "            'afib' as hist_AFIB_since_index,\n",
    "            'str' as hist_STR_since_index,\n",
    "            'ckd' as hist_CKD_since_index,\n",
    "            'copd' as hist_COPD_since_index,\n",
    "            'htn' as hist_HTN_since_index,\n",
    "            'hf' as hist_HF_since_index,\n",
    "            'aids' as hist_AIDS_since_index,\n",
    "            'hld' as hist_HLD_since_index,\n",
    "            'pvd' as hist_PVD_since_index,\n",
    "            'ra' as hist_RA_since_index,\n",
    "            'ad' as hist_AD_since_index,\n",
    "            'dm' as hist_DM_since_index,\n",
    "            'covid' as hist_COVID_since_index,\n",
    "            'sub' as hist_SUB_since_index,\n",
    "            'alc' as hist_ALC_since_index\n",
    "        )\n",
    "    )\n",
    "''').cache()\n",
    "comorb_pre_delivery_wide.createOrReplaceTempView(\"comorb_pre_delivery_wide\")\n",
    "comorb_pre_delivery_wide.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=11567, event_id=1, hist_HEP_since_index=None, hist_IHD_since_index=None, hist_AST_since_index=-351, hist_LIV_since_index=None, hist_AFIB_since_index=None, hist_STR_since_index=None, hist_CKD_since_index=None, hist_COPD_since_index=None, hist_HTN_since_index=None, hist_HF_since_index=None, hist_AIDS_since_index=None, hist_HLD_since_index=None, hist_PVD_since_index=None, hist_RA_since_index=None, hist_AD_since_index=None, hist_DM_since_index=None, hist_COVID_since_index=-845, hist_SUB_since_index=None, hist_ALC_since_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_elig_smm = spark.sql('''\n",
    "    with smm_any as (\n",
    "        select person_id, event_id, 1 as SMMANY_ind,\n",
    "               min(days_since_index) as SMMANY_since_index\n",
    "        from smm_post_delivery\n",
    "        group by person_id, event_id\n",
    "    )\n",
    "    select e.*,\n",
    "           case when e.age_at_event >=10 and e.age_at_event <20 then 'agegrp1'\n",
    "                when e.age_at_event >=20 and e.age_at_event <25 then 'agegrp2'\n",
    "                when e.age_at_event >=25 and e.age_at_event <30 then 'agegrp3'\n",
    "                when e.age_at_event >=30 and e.age_at_event <35 then 'agegrp4'\n",
    "                when e.age_at_event >=35 and e.age_at_event <40 then 'agegrp5'\n",
    "                else 'agegrp6' \n",
    "           end as agegrp_at_event,\n",
    "           case when los >= 2 then 1 else 0 end as los2up_ind,\n",
    "           case when los >= 3 then 1 else 0 end as los3up_ind,\n",
    "           case when los >= 4 then 1 else 0 end as los4up_ind,\n",
    "           case when los >= 5 then 1 else 0 end as los5up_ind,\n",
    "           case when los >= 6 then 1 else 0 end as los6up_ind,\n",
    "           case when los >= 7 then 1 else 0 end as los7up_ind,\n",
    "           cs.censor_since_index,\n",
    "           coalesce(datediff(e.death_date,e.event_start_date),cs.censor_since_index) as death_since_index,\n",
    "           coalesce(a.SMMANY_ind,0) as SMMANY_ind,\n",
    "           coalesce(a.SMMANY_since_index,cs.censor_since_index) as SMMANY_since_index,\n",
    "           coalesce(s.AMI_since_index,cs.censor_since_index) as AMI_since_index,\n",
    "           IF(s.AMI_since_index IS NOT NULL, 1, 0) AMI_ind,\n",
    "           coalesce(s.ANE_since_index,cs.censor_since_index) as ANE_since_index,\n",
    "           IF(s.ANE_since_index IS NOT NULL, 1, 0) ANE_ind,\n",
    "           coalesce(s.ARF_since_index,cs.censor_since_index) as ARF_since_index,\n",
    "           IF(s.ARF_since_index IS NOT NULL, 1, 0) ARF_ind,\n",
    "           coalesce(s.ARDS_since_index,cs.censor_since_index) as ARDS_since_index,\n",
    "           IF(s.ARDS_since_index IS NOT NULL, 1, 0) ARDS_ind,\n",
    "           coalesce(s.AFE_since_index,cs.censor_since_index) as AFE_since_index,\n",
    "           IF(s.AFE_since_index IS NOT NULL, 1, 0) AFE_ind,\n",
    "           coalesce(s.CAVF_since_index,cs.censor_since_index) as CAVF_since_index,\n",
    "           IF(s.CAVF_since_index IS NOT NULL, 1, 0) CAVF_ind,\n",
    "           coalesce(s.COCR_since_index,cs.censor_since_index) as COCR_since_index,\n",
    "           IF(s.COCR_since_index IS NOT NULL, 1, 0) COCR_ind,\n",
    "           coalesce(s.DIC_since_index,cs.censor_since_index) as DIC_since_index,\n",
    "           IF(s.DIC_since_index IS NOT NULL, 1, 0) DIC_ind,\n",
    "           coalesce(s.ECL_since_index,cs.censor_since_index) as ECL_since_index,\n",
    "           IF(s.ECL_since_index IS NOT NULL, 1, 0) ECL_ind,\n",
    "           coalesce(s.HF_since_index,cs.censor_since_index) as HF_since_index,\n",
    "           IF(s.HF_since_index IS NOT NULL, 1, 0) HF_ind,\n",
    "           coalesce(s.PCD_since_index,cs.censor_since_index) as PCD_since_index,\n",
    "           IF(s.PCD_since_index IS NOT NULL, 1, 0) PCD_ind,\n",
    "           coalesce(s.PE_since_index,cs.censor_since_index) as PE_since_index,\n",
    "           IF(s.PE_since_index IS NOT NULL, 1, 0) PE_ind,\n",
    "           coalesce(s.SAC_since_index,cs.censor_since_index) as SAC_since_index,\n",
    "           IF(s.SAC_since_index IS NOT NULL, 1, 0) SAC_ind,\n",
    "           coalesce(s.SEP_since_index,cs.censor_since_index) as SEP_since_index,\n",
    "           IF(s.SEP_since_index IS NOT NULL, 1, 0) SEP_ind,\n",
    "           coalesce(s.SSH_since_index,cs.censor_since_index) as SSH_since_index,\n",
    "           IF(s.SSH_since_index IS NOT NULL, 1, 0) SSH_ind,\n",
    "           coalesce(s.SCC_since_index,cs.censor_since_index) as SCC_since_index,\n",
    "           IF(s.SCC_since_index IS NOT NULL, 1, 0) SCC_ind,\n",
    "           coalesce(s.ATE_since_index,cs.censor_since_index) as ATE_since_index,\n",
    "           IF(s.ATE_since_index IS NOT NULL, 1, 0) ATE_ind,\n",
    "           coalesce(s.BPT_since_index,cs.censor_since_index) as BPT_since_index,\n",
    "           IF(s.BPT_since_index IS NOT NULL, 1, 0) BPT_ind,\n",
    "           coalesce(s.HYS_since_index,cs.censor_since_index) as HYS_since_index,\n",
    "           IF(s.HYS_since_index IS NOT NULL, 1, 0) HYS_ind,\n",
    "           coalesce(s.TT_since_index,cs.censor_since_index) as TT_since_index,\n",
    "           IF(s.TT_since_index IS NOT NULL, 1, 0) TT_ind,\n",
    "           coalesce(s.VEN_since_index,cs.censor_since_index) as VEN_since_index,\n",
    "           IF(s.VEN_since_index IS NOT NULL, 1, 0) VEN_ind,\n",
    "           cmb.hist_HEP_since_index,\n",
    "           IF(cmb.hist_HEP_since_index IS NOT NULL, 1, 0) hist_HEP_ind,\n",
    "           cmb.hist_IHD_since_index,\n",
    "           IF(cmb.hist_IHD_since_index IS NOT NULL, 1, 0) hist_IHD_ind,\n",
    "           cmb.hist_AST_since_index,\n",
    "           IF(cmb.hist_AST_since_index IS NOT NULL, 1, 0) hist_AST_ind,\n",
    "           cmb.hist_LIV_since_index,\n",
    "           IF(cmb.hist_LIV_since_index IS NOT NULL, 1, 0) hist_LIV_ind,\n",
    "           cmb.hist_AFIB_since_index,\n",
    "           IF(cmb.hist_AFIB_since_index IS NOT NULL, 1, 0) hist_AFIB_ind,\n",
    "           cmb.hist_STR_since_index,\n",
    "           IF(cmb.hist_STR_since_index IS NOT NULL, 1, 0) hist_STR_ind,\n",
    "           cmb.hist_CKD_since_index,\n",
    "           IF(cmb.hist_CKD_since_index IS NOT NULL, 1, 0) hist_CKD_ind,\n",
    "           cmb.hist_COPD_since_index,\n",
    "           IF(cmb.hist_COPD_since_index IS NOT NULL, 1, 0) hist_COPD_ind,\n",
    "           cmb.hist_HTN_since_index,\n",
    "           IF(cmb.hist_HTN_since_index IS NOT NULL, 1, 0) hist_HTN_ind,\n",
    "           cmb.hist_HF_since_index,\n",
    "           IF(cmb.hist_HF_since_index IS NOT NULL, 1, 0) hist_HF_ind,\n",
    "           cmb.hist_AIDS_since_index,\n",
    "           IF(cmb.hist_AIDS_since_index IS NOT NULL, 1, 0) hist_AIDS_ind,\n",
    "           cmb.hist_HLD_since_index,\n",
    "           IF(cmb.hist_HLD_since_index IS NOT NULL, 1, 0) hist_HLD_ind,\n",
    "           cmb.hist_PVD_since_index,\n",
    "           IF(cmb.hist_PVD_since_index IS NOT NULL, 1, 0) hist_PVD_ind,\n",
    "           cmb.hist_RA_since_index,\n",
    "           IF(cmb.hist_RA_since_index IS NOT NULL, 1, 0) hist_RA_ind,\n",
    "           cmb.hist_AD_since_index,\n",
    "           IF(cmb.hist_AD_since_index IS NOT NULL, 1, 0) hist_AD_ind,\n",
    "           cmb.hist_DM_since_index,\n",
    "           IF(cmb.hist_DM_since_index IS NOT NULL, 1, 0) hist_DM_ind,\n",
    "           cmb.hist_COVID_since_index,\n",
    "           IF(cmb.hist_COVID_since_index IS NOT NULL, 1, 0) hist_COVID_ind,\n",
    "           cmb.hist_SUB_since_index,\n",
    "           IF(cmb.hist_SUB_since_index IS NOT NULL, 1, 0) hist_SUB_ind,\n",
    "           cmb.hist_ALC_since_index,\n",
    "           IF(cmb.hist_ALC_since_index IS NOT NULL, 1, 0) hist_ALC_ind\n",
    "    from delivery_elig_tbl1 e\n",
    "    left join smm_any a \n",
    "    on e.person_id = a.person_id and e.event_id = a.event_id\n",
    "    left join smm_post_delivery_wide s \n",
    "    on e.person_id = s.person_id and e.event_id = s.event_id\n",
    "    left join delivery_elig_censor cs\n",
    "    on e.person_id = cs.person_id and e.event_id = cs.event_id\n",
    "    left join comorb_pre_delivery_wide cmb \n",
    "    on e.person_id = cmb.person_id and e.event_id = cmb.event_id \n",
    "    where cs.censor_since_index > 0  \n",
    "''').cache()\n",
    "# delivery_elig_smm.createOrReplaceTempView(\"delivery_elig_smm\")\n",
    "delivery_elig_smm.write.mode('overwrite').saveAsTable(\"delivery_elig_smm\")\n",
    "delivery_elig_smm.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=11567, event_id=1, event_start_date=datetime.date(2024, 3, 4), event_end_date=datetime.date(2024, 3, 5), delivery_type='d_v', los=1, visit_occurrence_id=17454747617679, year_of_birth=1990, age_at_event=34, race_source_value='American Indian or Alaska Native', ethnicity_source_value='Non-Hispanic', location_id=23, care_site_id=101, care_site_source_value='1', bed_size='200-299', speciality='Acute Care Hospital', segment='Hospital', zip_code='8', death_date=None, death_ind=0, delivery_idx=1, agegrp_at_event='agegrp5', los2up_ind=0, los3up_ind=0, los4up_ind=0, los5up_ind=0, los6up_ind=0, los7up_ind=0, censor_since_index=172, death_since_index=172, SMMANY_ind=0, SMMANY_since_index=172, AMI_since_index=172, AMI_ind=0, ANE_since_index=172, ANE_ind=0, ARF_since_index=172, ARF_ind=0, ARDS_since_index=172, ARDS_ind=0, AFE_since_index=172, AFE_ind=0, CAVF_since_index=172, CAVF_ind=0, COCR_since_index=172, COCR_ind=0, DIC_since_index=172, DIC_ind=0, ECL_since_index=172, ECL_ind=0, HF_since_index=172, HF_ind=0, PCD_since_index=172, PCD_ind=0, PE_since_index=172, PE_ind=0, SAC_since_index=172, SAC_ind=0, SEP_since_index=172, SEP_ind=0, SSH_since_index=172, SSH_ind=0, SCC_since_index=172, SCC_ind=0, ATE_since_index=172, ATE_ind=0, BPT_since_index=172, BPT_ind=0, HYS_since_index=172, HYS_ind=0, TT_since_index=172, TT_ind=0, VEN_since_index=172, VEN_ind=0, hist_HEP_since_index=None, hist_HEP_ind=0, hist_IHD_since_index=None, hist_IHD_ind=0, hist_AST_since_index=-351, hist_AST_ind=1, hist_LIV_since_index=None, hist_LIV_ind=0, hist_AFIB_since_index=None, hist_AFIB_ind=0, hist_STR_since_index=None, hist_STR_ind=0, hist_CKD_since_index=None, hist_CKD_ind=0, hist_COPD_since_index=None, hist_COPD_ind=0, hist_HTN_since_index=None, hist_HTN_ind=0, hist_HF_since_index=None, hist_HF_ind=0, hist_AIDS_since_index=None, hist_AIDS_ind=0, hist_HLD_since_index=None, hist_HLD_ind=0, hist_PVD_since_index=None, hist_PVD_ind=0, hist_RA_since_index=None, hist_RA_ind=0, hist_AD_since_index=None, hist_AD_ind=0, hist_DM_since_index=None, hist_DM_ind=0, hist_COVID_since_index=-845, hist_COVID_ind=1, hist_SUB_since_index=None, hist_SUB_ind=0, hist_ALC_since_index=None, hist_ALC_ind=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "delivery_elig_init_smm = spark.sql('''\n",
    "    with cte as (\n",
    "        select percentile(los,0.9) as los_90pct\n",
    "        from delivery_elig_smm\n",
    "    )\n",
    "    select a.*, \n",
    "           case when a.SMMANY_ind = 1 and a.los>=cte.los_90pct then 1 else 0 end as SMMANY90PCT_ind,\n",
    "           case when a.SMMANY_ind = 1 and a.los>=cte.los_90pct then SMMANY_since_index else censor_since_index end as SMMANY90PCT_since_index\n",
    "    from delivery_elig_smm a\n",
    "    cross join cte\n",
    "    where a.delivery_idx = 1 and \n",
    "          a.delivery_type in ('d_v','d_c')\n",
    "''').cache()\n",
    "# delivery_elig_init_smm.createOrReplaaceTempView(\"delivery_elig_init_smm\")\n",
    "delivery_elig_init_smm.write.mode('overwrite').saveAsTable(\"delivery_elig_init_smm\")\n",
    "delivery_elig_init_smm.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row(person_id=1047, event_id=1, event_start_date=datetime.date(2022, 6, 5), event_end_date=datetime.date(2022, 6, 8), delivery_type='d_v', los=3, visit_occurrence_id=17463337533175, year_of_birth=1996, age_at_event=26, race_source_value='White', ethnicity_source_value='Non-Hispanic', location_id=23, care_site_id=101, care_site_source_value='1', bed_size='200-299', speciality='Acute Care Hospital', segment='Hospital', zip_code='8', death_date=None, death_ind=0, delivery_idx=1, agegrp_at_event='agegrp4', los2up_ind=1, los3up_ind=1, los4up_ind=0, los5up_ind=0, los6up_ind=0, los7up_ind=0, censor_since_index=51, death_since_index=51, SMMANY_ind=0, SMMANY_since_index=51, AMI_since_index=51, AMI_ind=0, ANE_since_index=51, ANE_ind=0, ARF_since_index=51, ARF_ind=0, ARDS_since_index=51, ARDS_ind=0, AFE_since_index=51, AFE_ind=0, CAVF_since_index=51, CAVF_ind=0, COCR_since_index=51, COCR_ind=0, DIC_since_index=51, DIC_ind=0, ECL_since_index=51, ECL_ind=0, HF_since_index=51, HF_ind=0, PCD_since_index=51, PCD_ind=0, PE_since_index=51, PE_ind=0, SAC_since_index=51, SAC_ind=0, SEP_since_index=51, SEP_ind=0, SSH_since_index=51, SSH_ind=0, SCC_since_index=51, SCC_ind=0, ATE_since_index=51, ATE_ind=0, BPT_since_index=51, BPT_ind=0, HYS_since_index=51, HYS_ind=0, TT_since_index=51, TT_ind=0, VEN_since_index=51, VEN_ind=0, hist_HEP_since_index=None, hist_HEP_ind=0, hist_IHD_since_index=None, hist_IHD_ind=0, hist_AST_since_index=None, hist_AST_ind=0, hist_LIV_since_index=None, hist_LIV_ind=0, hist_AFIB_since_index=None, hist_AFIB_ind=0, hist_STR_since_index=None, hist_STR_ind=0, hist_CKD_since_index=None, hist_CKD_ind=0, hist_COPD_since_index=None, hist_COPD_ind=0, hist_HTN_since_index=-24, hist_HTN_ind=1, hist_HF_since_index=None, hist_HF_ind=0, hist_AIDS_since_index=None, hist_AIDS_ind=0, hist_HLD_since_index=None, hist_HLD_ind=0, hist_PVD_since_index=None, hist_PVD_ind=0, hist_RA_since_index=None, hist_RA_ind=0, hist_AD_since_index=None, hist_AD_ind=0, hist_DM_since_index=None, hist_DM_ind=0, hist_COVID_since_index=None, hist_COVID_ind=0, hist_SUB_since_index=None, hist_SUB_ind=0, hist_ALC_since_index=None, hist_ALC_ind=0, SMMANY90PCT_ind=0, SMMANY90PCT_since_index=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "    select count(distinct person_id), count(*)\n",
    "    from delivery_elig_init_smm\n",
    "''').toPandas()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
